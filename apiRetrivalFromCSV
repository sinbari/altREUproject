import requests
import pandas as pd
from itertools import product
import time 
import os
from concurrent.futures import ThreadPoolExecutor, as_completed

def download_function(drug, condition, sponsor): 
    url = "https://clinicaltrials.gov/api/v2/studies"  
    params = {
        "query.intr": drug,
        "query.cond": condition,
        "query.lead": sponsor, 
        "format": "json"
    }

    retries = 3
    for attempt in range(retries): 
        try:
            response = requests.get(url, params=params, timeout=10)
            if response.status_code == 200:
                print(f"API response for {drug}, {sponsor}, {condition}: {response.json()}")  # Add this line to print API response
                return response.json()
            else:
                print(f"Error: Received status code {response.status_code} for {drug}, {sponsor}, {condition}")
                return None
        except (ReadTimeout, ConnectionError) as e:
            print(f"{e} error for {drug}, {sponsor}, {condition}. Retrying ({attempt + 1}/{retries})...")
            time.sleep(5)
        except RequestException as e:
            print(f"RequestException error for {drug}, {sponsor}, {condition}: {e}")
            return None
    return None  

# Function to extract desired fields from the trial data
# def defines a function with a series of statements
def extract_trial_data(trial):
    fields = trial['Study']['ProtocolSection']
    return {
        'NCT Number': fields.get('IdentificationModule', {}).get('NCTId', ''),
        'Study Title': fields.get('IdentificationModule', {}).get('BriefTitle', ''),
        'Study URL': f"https://clinicaltrials.gov/ct2/show/{fields.get('IdentificationModule', {}).get('NCTId', '')}",
        'Acronym': fields.get('IdentificationModule', {}).get('Acronym', ''),
        'Study Status': fields.get('StatusModule', {}).get('OverallStatus', ''),
        'Brief Summary': fields.get('DescriptionModule', {}).get('BriefSummary', ''),
        'Study Results': fields.get('ResultsModule', {}).get('ResultsReference', {}).get('Citation', ''),
        'Conditions': fields.get('ConditionsModule', {}).get('ConditionList', {}).get('Condition', []),
        'Interventions': fields.get('ArmsInterventionsModule', {}).get('InterventionList', {}).get('Intervention', []),
        'Primary Outcome Measures': fields.get('OutcomesModule', {}).get('PrimaryOutcomeList', {}).get('PrimaryOutcome', []),
        'Secondary Outcome Measures': fields.get('OutcomesModule', {}).get('SecondaryOutcomeList', {}).get('SecondaryOutcome', []),
        'Other Outcome Measures': fields.get('OutcomesModule', {}).get('OtherOutcomeList', {}).get('OtherOutcome', []),
        'Sponsor': fields.get('SponsorCollaboratorsModule', {}).get('LeadSponsor', {}).get('LeadSponsorName', ''),
        'Collaborators': fields.get('SponsorCollaboratorsModule', {}).get('CollaboratorList', {}).get('Collaborator', []),
        'Sex': fields.get('EligibilityModule', {}).get('Gender', ''),
        'Age': fields.get('EligibilityModule', {}).get('MinimumAge', '') + " to " + fields.get('EligibilityModule', {}).get('MaximumAge', ''),
        'Phases': fields.get('DesignModule', {}).get('PhaseList', {}).get('Phase', []),
        'Enrollment': fields.get('DesignModule', {}).get('EnrollmentInfo', {}).get('EnrollmentCount', ''),
        'Funder Type': fields.get('SponsorCollaboratorsModule', {}).get('LeadSponsor', {}).get('LeadSponsorClass', ''),
        'Study Type': fields.get('DesignModule', {}).get('StudyType', ''),
        'Study Design': fields.get('DesignModule', {}).get('DesignInfo', {}).get('DesignAllocation', ''),
        'Other IDs': fields.get('IdentificationModule', {}).get('SecondaryIdInfoList', {}).get('SecondaryIdInfo', []),
        'Start Date': fields.get('StatusModule', {}).get('StartDateStruct', {}).get('StartDate', ''),
        'Primary Completion Date': fields.get('StatusModule', {}).get('PrimaryCompletionDateStruct', {}).get('PrimaryCompletionDate', ''),
        'Completion Date': fields.get('StatusModule', {}).get('CompletionDateStruct', {}).get('CompletionDate', ''),
        'First Posted': fields.get('ResultsFirstPostDateStruct', {}).get('ResultsFirstPostDate', ''),
        'Results First Posted': fields.get('ResultsFirstPostDateStruct', {}).get('ResultsFirstPostDate', ''),
        'Last Update Posted': fields.get('LastUpdatePostDateStruct', {}).get('LastUpdatePostDate', ''),
        'Locations': fields.get('ContactsLocationsModule', {}).get('LocationList', {}).get('Location', []),
        'Study Documents': fields.get('DocumentsModule', {}).get('DocumentList', {}).get('Document', []),
    }


# Read the CSV file 
my_csv_sheet1 = r"C:\Users\yello\Downloads\All_Designated_Drugs.csv"

df_sheet1 = pd.read_csv(my_csv_sheet1, encoding='latin1')


#Drop rows with missing values in drug sponsor or condition
df_sheet1 = df_sheet1.dropna(subset=['Drug', 'Sponsor', 'Condition'])


# Define status filters
statuses_sheet1 = [
    "ACTIVE_NOT_RECRUITING", "ENROLLING_BY_INVITATION", "NOT_YET_RECRUITING",
    "RECRUITING", "AVAILABLE"
]




# Process each row in parallel 
def process_row(row):
    drug = row['Drug']
    sponsor = row['Sponsor']
    condition = row['Condition']

    #Check for missing fields
    if pd.isna(drug) or pd.isna(sponsor) or pd.isna(condition): 
            print(f"Skipping row wiht missing values: {drug}, {sponsor}, {condition}")
            return []
    
    print(f"Fetching data for {drug}, {sponsor}, and {condition}")
    trial_info = download_function(drug, sponsor, condition)
    results = []
    if trial_info and 'FullStudiesResponse' in trial_info and 'FullStudies' in trial_info['FullStudiesResponse']:
        for study in trial_info['FullStudiesResponse']['FullStudies']:
            trial_data = extract_trial_data(study)
            results.append(trial_data)
            print(f"Extracted trial data: {trial_data}")
    return results

# Process the DataFrame using parallel processing
def process_sheet_parallel(df):
    results = []
    with ThreadPoolExecutor(max_workers=10) as executor:
        future_to_row = {executor.submit(process_row, row): row for _, row in df.iterrows()}
        for future in as_completed(future_to_row):
            try:
                data = future.result()
                if data:
                    results.extend(data)
            except Exception as e:
                print(f"Exception: {e}")
    return results

# process each file 
results_sheet1 = process_sheet_parallel(df_sheet1)


# Convert results to DataFrame
results_df_sheet1 = pd.DataFrame(results_sheet1)


print(f"Results Dataframe: {results_df_sheet1}") # prints df 
# Specify the folder path 
folder_path = r'C:\Users\yello\Downloads\Data_altREU'

# Ensure the folder exists
os.makedirs(folder_path, exist_ok=True)

# Save new CSV files in sepcified folder
output_file_path_sheet1 = os.path.join(folder_path, 'API_trials__Designated.csv')


results_df_sheet1.to_csv(output_file_path_sheet1, index=False)



print(f"Results for Sheet1 saved to {output_file_path_sheet1}")




